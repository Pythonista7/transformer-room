{
  "model_name": "baseline_decoder",
  "tokenizer_name": "bpe",
  "base_vocab_size": 33280,
  "num_special_tokens": 3,
  "vocab_size": 33283,
  "d_model": 128,
  "n_heads": 8,
  "layers": 2,
  "training_seq_len": 128,
  "tokenizer_vocab_path": "/Users/ashwinm4p/ash/code/transformer-room/baseline/tokenizers/wikitext2_v1_hf_vocab_bpe.txt"
}