{
  "run": {
    "project_name": "transformer-room-baseline",
    "run_name": "wikitext2_gpt2_v1",
    "artifacts_root": "/Users/ashwinm4p/ash/code/transformer-room/baseline/models",
    "resume_from_checkpoint": true,
    "checkpoint_every_n_steps": 250,
    "checkpoint_filename": "baseline_checkpoint.pt",
    "final_model_filename": "baseline_model.pt",
    "use_torch_compile": true,
    "torch_compile_mode": "default",
    "torch_compile_fullgraph": false,
    "torch_compile_dynamic": false
  },
  "dataset": {
    "name": "hf_text",
    "dataset_name": "Salesforce/wikitext",
    "dataset_config": "wikitext-2-v1",
    "split": "train",
    "text_field": "text",
    "streaming": false,
    "max_rows": 0
  },
  "tokenizer": {
    "name": "bpe",
    "base_vocab_size": 33280,
    "num_special_tokens": 3,
    "vocab_path": "/Users/ashwinm4p/ash/code/transformer-room/baseline/tokenizers/wikitext2_v1_hf_vocab_bpe.txt"
  },
  "model": {
    "name": "baseline_decoder",
    "d_model": 128,
    "n_heads": 8,
    "layers": 2
  },
  "train": {
    "epochs": 3,
    "learning_rate": 0.001,
    "batch_size": 256,
    "seq_len": 128,
    "stride": 128,
    "data_fraction": 1.0
  },
  "split": {
    "name": "holdout",
    "train_fraction": 0.9,
    "seed": 42,
    "shuffle": false
  },
  "logging": {
    "provider": "console"
  }
}